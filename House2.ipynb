{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn import linear_model # Scikit learn library that implements generalized linear models\n",
    "from sklearn import neighbors # provides functionality for unsupervised and supervised neighbors-based learning methods\n",
    "from sklearn.metrics import mean_squared_error # Mean squared error regression loss\n",
    "from sklearn import preprocessing # provides functions and classes to change raw feature vectors\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\i313684\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\i313684\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\i313684\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\i313684\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../downloads/housepricedata.csv')\n",
    "\n",
    "# Part 1 -----  Study of Categorical data -- \n",
    "# -----   Base Features  - All the Features except Following Data\n",
    "# ---- Categorical Features - cat_cols = ['floors', 'view', 'condition', 'grade', 'sqft_basement', 'yr_renovated']\n",
    "# ------ Use Base featues + One Cat Feature, Perform Linear regression -- Total 6 models\n",
    "# Q1 : Plot RMSE and R for each model on the Same plot and observe effect of each Feature\n",
    "train_data, test_data = train_test_split(df, train_size = 0.8)\n",
    "\n",
    "df['waterfront'] = df['waterfront'].astype('category',ordered=True)\n",
    "df['view'] = df['view'].astype('category',ordered=True)\n",
    "df['condition'] = df['condition'].astype('category',ordered=True)\n",
    "df['grade'] = df['grade'].astype('category',ordered=False)\n",
    "df['zipcode'] = df['zipcode'].astype(str)\n",
    "\n",
    "# A joint plot is used to visualize the bivariate distribution\n",
    "#sns.jointplot(x=\"sqft_living\", y=\"price\", data=df, kind = 'reg', size = 10)\n",
    "#sns.jointplot(x=\"sqft_lot\", y=\"price\", data=df, kind = 'reg', size = 10)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256399.75098249599, -46086.52015962463, 282.2042837333545)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\i313684\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\ipykernel_launcher.py:22: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\i313684\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\ipykernel_launcher.py:23: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\i313684\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read these four as categorical variables\n",
    "cat_cols = ['floors', 'view', 'condition', 'grade']\n",
    "\n",
    "for cc in cat_cols:\n",
    "    dummies = pd.get_dummies(df[cc], drop_first=False)\n",
    "    dummies = dummies.add_prefix(\"{}#\".format(cc))\n",
    "    df.drop(cc, axis=1, inplace=True)\n",
    "    df = df.join(dummies)\n",
    "\n",
    "\n",
    "#------ part2 --- Making use of a function for iterative model evaluation\n",
    "#------ Part 1 above can be performed easily using this function\n",
    "# Q2 : Perform the same analysis by performing iterations on the following Function\n",
    "# A function that take one input of the dataset \n",
    "# and return the RMSE, R, and Bias-parameter (intercept)\n",
    "\n",
    "train_data, test_data = train_test_split(df, train_size = 0.8)\n",
    "\n",
    "def simple_linear_model(train, test, input_feature):\n",
    "    lm = linear_model.LinearRegression() # Create a linear regression object\n",
    "    lm.fit(train.as_matrix(columns = [input_feature]), train.as_matrix(columns = ['price'])) # Train the model\n",
    "    RMSE = mean_squared_error(test.as_matrix(columns = ['price']), \n",
    "                              lm.predict(test.as_matrix(columns = [input_feature])))**0.5 # Calculate the RMSE on test data\n",
    "    return RMSE, lm.intercept_[0], lm.coef_[0][0]\n",
    "\n",
    "\n",
    "RMSE, w0, w1 = simple_linear_model(train_data, test_data, 'sqft_living')\n",
    "print(RMSE, w0, w1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53893586739.786476\n",
      "Variance score: 0.61\n"
     ]
    }
   ],
   "source": [
    "lm = linear_model.LinearRegression() # Create a linear regression object\n",
    "dummies_zipcodes = pd.get_dummies(df['zipcode'], drop_first=True)\n",
    "dummies_zipcodes.reset_index(inplace=True)\n",
    "dummies_zipcodes = dummies_zipcodes.add_prefix(\"{}#\".format('zipcode'))\n",
    "df.drop('zipcode', axis=1, inplace=True)\n",
    "# total 70 zipcodes exist\n",
    "\n",
    "\n",
    "other_features = ['sqft_living']\n",
    "dummies_zipcodes_partial = dummies_zipcodes[['zipcode#98004','zipcode#98102','zipcode#98109','zipcode#98112','zipcode#98039','zipcode#98040']]\n",
    "#dummies_zipcodes_partial = dummies_zipcodes[['zipcode#98004']]\n",
    "\n",
    "df_short = df.select_dtypes(include=['float64', 'int64'])\n",
    "df_new = df[other_features].join(dummies_zipcodes_partial)\n",
    "y = df['price']\n",
    "\n",
    "\n",
    "# Model evaluation using train_test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_new, y, test_size=0.3, random_state=0)\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "print(metrics.mean_squared_error(y_test, lm.predict(X_test)))\n",
    "print('Variance score: %.2f' % lm.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Size of Train data : ', 0.1)\n",
      "4.1201628295949833e-16\n",
      "3.9497253247809055e-16\n",
      "Variance score: 1.00\n",
      "('Size of Train data : ', 0.2)\n",
      "1.897143815327483e-16\n",
      "1.772569556119688e-16\n",
      "Variance score: 1.00\n",
      "('Size of Train data : ', 0.30000000000000004)\n",
      "1.0912976690588541e-16\n",
      "1.0902574645843499e-16\n",
      "Variance score: 1.00\n",
      "('Size of Train data : ', 0.4)\n",
      "1.035200334530895e-16\n",
      "1.069218270597548e-16\n",
      "Variance score: 1.00\n",
      "('Size of Train data : ', 0.5)\n",
      "1.6342355715833056e-16\n",
      "1.6047962157335176e-16\n",
      "Variance score: 1.00\n",
      "('Size of Train data : ', 0.6000000000000001)\n",
      "2.6942098831430923e-16\n",
      "2.6163639838586753e-16\n",
      "Variance score: 1.00\n",
      "('Size of Train data : ', 0.7000000000000001)\n",
      "1.121055075780555e-16\n",
      "1.8676180531279284e-16\n",
      "Variance score: 1.00\n",
      "('Size of Train data : ', 0.8)\n",
      "1.5768515379883548e-16\n",
      "2.9503614481622993e-16\n",
      "Variance score: 1.00\n",
      "('Size of Train data : ', 0.9)\n",
      "7.663430002671024e-17\n",
      "1.0290930343168563e-16\n",
      "Variance score: 1.00\n",
      "59104002420.98609\n",
      "Variance score: 0.57\n",
      "58902317933.51474\n",
      "Variance score: 0.56\n",
      "[0.63382975 0.64529402 0.51751287 0.54321238 0.62825799]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_new, y, test_size=0.1*i, random_state=0)\n",
    "    lm.fit(X_train, y_train)\n",
    "    print(\"Size of Train data : \", 0.1*i)\n",
    "    print(metrics.mean_squared_error(y_train, lm.predict(X_train)))\n",
    "    print(metrics.mean_squared_error(y_test, lm.predict(X_test)))\n",
    "    print('Variance score: %.2f' % lm.score(X_test, y_test))\n",
    "    \n",
    "    \n",
    "# --------- Part 5 :  Add polynomial features for sqft_living to boost the accuracy\n",
    "# ------  Use Features = Base Features + ALL Categorical features + Exotic_features\n",
    "# ------- By Plotting Train and Test error, with one Exotic_feature at a time,\n",
    "# -----   Compare the J_test and J_train to check for bias\n",
    "\n",
    "dummies_zipcodes_partial = dummies_zipcodes[['zipcode#98004','zipcode#98102','zipcode#98109','zipcode#98112','zipcode#98039','zipcode#98040']]\n",
    "df_new = df_short[other_features].join(dummies_zipcodes_partial)\n",
    "\n",
    "#Exotic1A\n",
    "df_new['sqft_living_squared'] = df_new['sqft_living'].apply(lambda x: x**2) \n",
    "#Exotic1B\n",
    "df_new['sqft_living_cubed'] = df_new['sqft_living'].apply(lambda x: x**3) \n",
    "#Exotic1C  \n",
    "df_new['sqft_living_quad'] = df_new['sqft_living'].apply(lambda x: x**4) \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_new, y, test_size=0.3, random_state=0)\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "print(metrics.mean_squared_error(y_test, lm.predict(X_test)))\n",
    "print('Variance score: %.2f' % lm.score(X_test, y_test))\n",
    "print(metrics.mean_squared_error(y_train, lm.predict(X_train)))\n",
    "print('Variance score: %.2f' % lm.score(X_train, y_train))\n",
    "\n",
    "\n",
    "#  - ---    Lets add polynomial terms of few other features also\n",
    "del df_new\n",
    "other_features = ['sqft_living']\n",
    "\n",
    "dummies_zipcodes_partial = dummies_zipcodes[['zipcode#98004','zipcode#98102','zipcode#98109','zipcode#98112','zipcode#98039','zipcode#98040']]\n",
    "df_new = df[other_features].join(dummies_zipcodes_partial)\n",
    "\n",
    "# #Exotic2 : sqft_living cubed\n",
    "df_new['sqft_living_cubed'] = df['sqft_living'].apply(lambda x: x**3) \n",
    "\n",
    "# #Exotic3 : bedrooms_squared: this feature will mostly affect houses with many bedrooms.\n",
    "df_new['bedrooms_squared'] = df['bedrooms'].apply(lambda x: x**2) \n",
    "\n",
    "# #Exotic4 : bedrooms times bathrooms gives what's called an \"interaction\" feature. It is large when both of them are large.\n",
    "df_new['bed_bath_rooms'] = df['bedrooms']*df['bathrooms']\n",
    "\n",
    "# #Exotic5 : bringing large values closer together and spreading out small values.\n",
    "df_new['log_sqft_living'] = df['sqft_living'].apply(lambda x: log(x))\n",
    "\n",
    "\n",
    "# ----   Part6 :   Cross validation methods\n",
    "\n",
    "scores = cross_val_score(lm, df_new, y, cv=5)\n",
    "print(scores)\n",
    "\n",
    "# Assign 3 :  Make 10 blocks, average of coefficients (PLot price vs. sqft-living)\n",
    "\n",
    "# ---- Part7 : Regularisation using L2 norm\n",
    "# ----  Perform Regularisation for Features = ['floors', 'view', 'condition', 'grade'] and,\n",
    "# ----  Polynomial features of Sqft_living\n",
    "#  --- Make a plot of J_train and J_test with and without regularisation, for different values of lambda (alpha)\n",
    "del df_new\n",
    "\n",
    "cat_cols = ['floors', 'view', 'condition', 'grade']    \n",
    "df_short = df.select_dtypes(include=['float64', 'int64'])\n",
    "df_new = pd.concat([df, dummies],axis=1)\n",
    "df_new['sqft_living_squared'] = df_new['sqft_living'].apply(lambda x: x**2) \n",
    "df_new['sqft_living_cubed'] = df_new['sqft_living'].apply(lambda x: x**3)     \n",
    "df_new['sqft_living_quad'] = df_new['sqft_living'].apply(lambda x: x**4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy Score  : 56.9501316947\n",
      "62699139792.07469\n",
      "Variance score: 0.54\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#-------- part 3 Using large number of variables in modeling\n",
    "# ------  Use Features = Base Features + ALL Categorical features + dummies_Zipcode\n",
    "# ------   Q3 : Use three sets of dummies_zipcodes [2, 5, 70] in numbers\n",
    "# -------  And plot RMSE for each case, for both J_train  and J_test \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------- Part4  : Get RMSE for test, train of different size of data-sets\n",
    "# Assignment : Randomize the data. Then plot the learning curves  for J_train  and J_test\n",
    "#              Train vs. Test error for 10 data-set splits  from 0% to 90%\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,normalize=False)\n",
    "model.fit(X_train, y_train)\n",
    "result = model.score(X_test, y_test)\n",
    "finalResult = result*100\n",
    "print(\"The Accuracy Score  : {}\". format(finalResult))\n",
    " \n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "regr = linear_model.Ridge(alpha=10000000000000.0)\n",
    "regr.fit(X_train, y_train)\n",
    "print(metrics.mean_squared_error(y_test, regr.predict(X_test)))\n",
    "print('Variance score: %.2f' % regr.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
